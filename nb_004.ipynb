{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMEonenjWwJ3sVcTakAsxV4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prisar/ai/blob/main/nb_004.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run cuda codes in notebook "
      ],
      "metadata": {
        "id": "dExiyWyai4V-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3jQ0F89ZPnj",
        "outputId": "947f935d-0c3d-4009-a599-34a8b6aa66ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin    cuda\tcuda-11.8  games\t       include\tlib64\t   man\t share\n",
            "colab  cuda-11\tetc\t   _gcs_config_ops.so  lib\tlicensing  sbin  src\n"
          ]
        }
      ],
      "source": [
        "!ls /usr/local/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!which nvcc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24c198hNZi7y",
        "outputId": "dc47d503-10b2-48aa-aeb6-9da03ce14a36"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/cuda/bin/nvcc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTQmrvhVZlM0",
        "outputId": "af680a0d-59ff-4b25-9960-8c8ce14317ab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri May 26 09:31:58 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile hello.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "__global__ void hello(void)\n",
        "{\n",
        "    printf(\"GPU: Hello!\\n\");\n",
        "}\n",
        "int main(int argc,char **argv)\n",
        "{\n",
        "    printf(\"CPU: Hello!\\n\");\n",
        "    hello<<<1,10>>>();\n",
        "    cudaDeviceReset();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmUcL6uSZn6i",
        "outputId": "df95c3e4-08a8-493a-e8b4-dc21b342fc58"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hello.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Method 1\n",
        "!nvcc -arch=sm_37  -Wno-deprecated-gpu-targets -gencode=arch=compute_37,code=sm_37 hello.cu -o hello\n"
      ],
      "metadata": {
        "id": "XgJb0pV2aOU5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./hello"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSCjeBUkbG7M",
        "outputId": "c7cb73b0-797c-44a2-edc9-8ca66fbc1780"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile max_element.cu\n",
        "\n",
        "#include <cstdio>\n",
        "#include <iostream>\n",
        " \n",
        "using namespace std;\n",
        " \n",
        "__global__ void maxi(int* a, int* b, int n)\n",
        "{\n",
        "    int block = 256 * blockIdx.x;\n",
        "    int max = 0;\n",
        " \n",
        "    for (int i = block; i < min(256 + block, n); i++) {\n",
        " \n",
        "        if (max < a[i]) {\n",
        "            max = a[i];\n",
        "        }\n",
        "    }\n",
        "    b[blockIdx.x] = max;\n",
        "}\n",
        " \n",
        "int main()\n",
        "{\n",
        " \n",
        "    int n;\n",
        "    n = 3 >> 2;\n",
        "    int a[n];\n",
        " \n",
        "    for (int i = 0; i < n; i++) {\n",
        "        a[i] = rand() % n;\n",
        "        cout << a[i] << \"\\t\";\n",
        "    }\n",
        " \n",
        "    cudaEvent_t start, end;\n",
        "    int *ad, *bd;\n",
        "    int size = n * sizeof(int);\n",
        "    cudaMalloc(&ad, size);\n",
        "    cudaMemcpy(ad, a, size, cudaMemcpyHostToDevice);\n",
        "    int grids = ceil(n * 1.0f / 256.0f);\n",
        "    cudaMalloc(&bd, grids * sizeof(int));\n",
        " \n",
        "    dim3 grid(grids, 1);\n",
        "    dim3 block(1, 1);\n",
        " \n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&end);\n",
        "    cudaEventRecord(start);\n",
        " \n",
        "    while (n > 1) {\n",
        "        maxi<<<grids, block>>>(ad, bd, n);\n",
        "        n = ceil(n * 1.0f / 256.0f);\n",
        "        cudaMemcpy(ad, bd, n * sizeof(int), cudaMemcpyDeviceToDevice);\n",
        "    }\n",
        " \n",
        "    cudaEventRecord(end);\n",
        "    cudaEventSynchronize(end);\n",
        " \n",
        "    float time = 0;\n",
        "    cudaEventElapsedTime(&time, start, end);\n",
        " \n",
        "    int ans[2];\n",
        "    cudaMemcpy(ans, ad, 4, cudaMemcpyDeviceToHost);\n",
        " \n",
        "    cout << \"The maximum element is : \" << ans[0] << endl;\n",
        " \n",
        "    cout << \"The time required : \";\n",
        "    cout << time << endl;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CUGU1v2b_OD",
        "outputId": "9f5ffb7e-32c6-44c7-b196-fe94ede153d1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing max_element.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_37  -Wno-deprecated-gpu-targets -gencode=arch=compute_37,code=sm_37 max_element.cu -o max_element\n",
        "!./max_element\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUTGqVBpcSzK",
        "outputId": "afc069c6-52aa-4a30-fdc9-1cad8e9ddf38"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The maximum element is : 0\n",
            "The time required : 0.003008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cuda programs are from this source: https://web.mit.edu/pocky/www/cudaworkshop/WorkshopFiles.html"
      ],
      "metadata": {
        "id": "_gGs-ZKDfGzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_add.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "\n",
        "#define N 4096         // size of array\n",
        "\n",
        "__global__ void add(int *a,int *b, int *c) {\n",
        "\tint tid = blockIdx.x *  blockDim.x + threadIdx.x;\n",
        "        if(tid < N){\n",
        "          c[tid] = a[tid]+b[tid];\n",
        "        }\n",
        "}\n",
        "\n",
        "int main(int argc, char *argv[])  {\n",
        "\tint T = 10, B = 1;            // threads per block and blocks per grid\n",
        "\tint a[N],b[N],c[N];\n",
        "\tint *dev_a, *dev_b, *dev_c;\n",
        "\n",
        "\tprintf(\"Size of array = %d\\n\", N);\n",
        "\tdo {\n",
        "\t\tprintf(\"Enter number of threads per block: \");\n",
        "\t\tscanf(\"%d\",&T);\n",
        "\t\tprintf(\"\\nEnter nuumber of blocks per grid: \");\n",
        "\t\tscanf(\"%d\",&B);\n",
        "\t\tif (T * B != N) printf(\"Error T x B != N, try again\");\n",
        "\t} while (T * B != N);\n",
        "\n",
        "\tcudaEvent_t start, stop;     // using cuda events to measure time\n",
        "\tfloat elapsed_time_ms;       // which is applicable for asynchronous code also\n",
        "\n",
        "\tcudaMalloc((void**)&dev_a,N * sizeof(int));\n",
        "\tcudaMalloc((void**)&dev_b,N * sizeof(int));\n",
        "\tcudaMalloc((void**)&dev_c,N * sizeof(int));\n",
        "\n",
        "\tfor(int i=0;i<N;i++) {    // load arrays with some numbers\n",
        "\t\ta[i] = i;\n",
        "\t\tb[i] = i*1;\n",
        "\t}\n",
        "\n",
        "\tcudaMemcpy(dev_a, a , N*sizeof(int),cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(dev_b, b , N*sizeof(int),cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(dev_c, c , N*sizeof(int),cudaMemcpyHostToDevice);\n",
        "\n",
        "\tcudaEventCreate( &start );     // instrument code to measure start time\n",
        "\tcudaEventCreate( &stop );\n",
        "\tcudaEventRecord( start, 0 );\n",
        "\n",
        "\tadd<<<B,T>>>(dev_a,dev_b,dev_c);\n",
        "\n",
        "\tcudaMemcpy(c,dev_c,N*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "\n",
        "\tcudaEventRecord( stop, 0 );     // instrument code to measue end time\n",
        "\tcudaEventSynchronize( stop );\n",
        "\tcudaEventElapsedTime( &elapsed_time_ms, start, stop );\n",
        "\n",
        "\tfor(int i=0;i<N;i++) {\n",
        "\t\tprintf(\"%d+%d=%d\\n\",a[i],b[i],c[i]);\n",
        "\t}\n",
        "\n",
        "\tprintf(\"Time to calculate results: %f ms.\\n\", elapsed_time_ms);  // print out execution time\n",
        "\n",
        "\t// clean up\n",
        "\tcudaFree(dev_a);\n",
        "\tcudaFree(dev_b);\n",
        "\tcudaFree(dev_c);\n",
        "\n",
        "\tcudaEventDestroy(start);\n",
        "\tcudaEventDestroy(stop);\n",
        "\n",
        "\treturn 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHA43UcSdyW6",
        "outputId": "6cbe683e-6ef7-43b7-b543-62ea7213049a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vector_add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_37  -Wno-deprecated-gpu-targets -gencode=arch=compute_37,code=sm_37 vector_add.cu -o vector_add\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40QqyxNSd6_U",
        "outputId": "8d11e937-ce58-48e2-f9bf-8453f8d079b0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: 16: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_add_input.txt\n",
        "16 256"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJr_cfu5eY8b",
        "outputId": "e4dc8538-3cd1-4f68-8280-1e41c2916b85"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vector_add_input.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./vector_add < vector_add_input.txt"
      ],
      "metadata": {
        "id": "9XtXljRieldi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Pi.cu\n",
        "\n",
        "// Written by Barry Wilkinson, UNC-Charlotte. Pi.cu  December 22, 2010.\n",
        "//Derived somewhat from code developed by Patrick Rogers, UNC-C\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "#include <math.h>\n",
        "#include <time.h>\n",
        "#include <curand_kernel.h>\n",
        "\n",
        "#define TRIALS_PER_THREAD 4096\n",
        "#define BLOCKS 256\n",
        "#define THREADS 256\n",
        "#define PI 3.1415926535  // known value of pi\n",
        "\n",
        "__global__ void gpu_monte_carlo(float *estimate, curandState *states) {\n",
        "\tunsigned int tid = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "\tint points_in_circle = 0;\n",
        "\tfloat x, y;\n",
        "\n",
        "\tcurand_init(1234, tid, 0, &states[tid]);  // \tInitialize CURAND\n",
        "\n",
        "\n",
        "\tfor(int i = 0; i < TRIALS_PER_THREAD; i++) {\n",
        "\t\tx = curand_uniform (&states[tid]);\n",
        "\t\ty = curand_uniform (&states[tid]);\n",
        "\t\tpoints_in_circle += (x*x + y*y <= 1.0f); // count if x & y is in the circle.\n",
        "\t}\n",
        "\testimate[tid] = 4.0f * points_in_circle / (float) TRIALS_PER_THREAD; // return estimate of pi\n",
        "}\n",
        "\n",
        "float host_monte_carlo(long trials) {\n",
        "\tfloat x, y;\n",
        "\tlong points_in_circle;\n",
        "\tfor(long i = 0; i < trials; i++) {\n",
        "\t\tx = rand() / (float) RAND_MAX;\n",
        "\t\ty = rand() / (float) RAND_MAX;\n",
        "\t\tpoints_in_circle += (x*x + y*y <= 1.0f);\n",
        "\t}\n",
        "\treturn 4.0f * points_in_circle / trials;\n",
        "}\n",
        "\n",
        "int main (int argc, char *argv[]) {\n",
        "\tclock_t start, stop;\n",
        "\tfloat host[BLOCKS * THREADS];\n",
        "\tfloat *dev;\n",
        "\tcurandState *devStates;\n",
        "\n",
        "\tprintf(\"# of trials per thread = %d, # of blocks = %d, # of threads/block = %d.\\n\", TRIALS_PER_THREAD,\n",
        "BLOCKS, THREADS);\n",
        "\n",
        "\tstart = clock();\n",
        "\n",
        "\tcudaMalloc((void **) &dev, BLOCKS * THREADS * sizeof(float)); // allocate device mem. for counts\n",
        "\t\n",
        "\tcudaMalloc( (void **)&devStates, THREADS * BLOCKS * sizeof(curandState) );\n",
        "\n",
        "\tgpu_monte_carlo<<<BLOCKS, THREADS>>>(dev, devStates);\n",
        "\n",
        "\tcudaMemcpy(host, dev, BLOCKS * THREADS * sizeof(float), cudaMemcpyDeviceToHost); // return results \n",
        "\n",
        "\tfloat pi_gpu;\n",
        "\tfor(int i = 0; i < BLOCKS * THREADS; i++) {\n",
        "\t\tpi_gpu += host[i];\n",
        "\t}\n",
        "\n",
        "\tpi_gpu /= (BLOCKS * THREADS);\n",
        "\n",
        "\tstop = clock();\n",
        "\n",
        "\tprintf(\"GPU pi calculated in %f s.\\n\", (stop-start)/(float)CLOCKS_PER_SEC);\n",
        "\n",
        "\tstart = clock();\n",
        "\tfloat pi_cpu = host_monte_carlo(BLOCKS * THREADS * TRIALS_PER_THREAD);\n",
        "\tstop = clock();\n",
        "\tprintf(\"CPU pi calculated in %f s.\\n\", (stop-start)/(float)CLOCKS_PER_SEC);\n",
        "\n",
        "\tprintf(\"CUDA estimate of PI = %f [error of %f]\\n\", pi_gpu, pi_gpu - PI);\n",
        "\tprintf(\"CPU estimate of PI = %f [error of %f]\\n\", pi_cpu, pi_cpu - PI);\n",
        "\t\n",
        "\treturn 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtqwIja3fXog",
        "outputId": "f932a528-ad99-46fb-be76-4ee5a7e0430e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Pi.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_37  -Wno-deprecated-gpu-targets -gencode=arch=compute_37,code=sm_37 Pi.cu -o Pi\n",
        "!./Pi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i6uf6i6fxIY",
        "outputId": "a6e0d483-f504-4c6e-d10b-019719c4c28f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of trials per thread = 4096, # of blocks = 256, # of threads/block = 256.\n",
            "GPU pi calculated in 0.401710 s.\n",
            "CPU pi calculated in 10.019849 s.\n",
            "CUDA estimate of PI = 3.141582 [error of -0.000011]\n",
            "CPU estimate of PI = 3.141581 [error of -0.000012]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from numba import cuda\n",
        "\n",
        "@cuda.reduce\n",
        "def sum_reduce(a, b):\n",
        "    return a + b\n",
        "\n",
        "A = (numpy.arange(1234, dtype=numpy.float64)) + 1\n",
        "expect = A.sum()      # NumPy sum reduction\n",
        "got = sum_reduce(A)   # cuda sum reduction\n",
        "assert expect == got"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qK3vIO3uhUu8",
        "outputId": "8f3b8651-a108-465d-8aff-f5b18420e3cd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 9 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "761995.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:885: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        }
      ]
    }
  ]
}